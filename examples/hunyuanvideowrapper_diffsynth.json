{
  "last_node_id": 57,
  "last_link_id": 75,
  "nodes": [
    {
      "id": 34,
      "type": "VHS_VideoCombine",
      "pos": [
        847.0758666992188,
        -415.1882629394531
      ],
      "size": [
        512.8807373046875,
        1128.39453125
      ],
      "flags": {},
      "order": 9,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 69
        },
        {
          "name": "audio",
          "type": "AUDIO",
          "link": null,
          "shape": 7
        },
        {
          "name": "meta_batch",
          "type": "VHS_BatchManager",
          "link": null,
          "shape": 7
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": null,
          "shape": 7
        }
      ],
      "outputs": [
        {
          "name": "Filenames",
          "type": "VHS_FILENAMES",
          "links": null
        }
      ],
      "properties": {
        "Node name for S&R": "VHS_VideoCombine"
      },
      "widgets_values": {
        "frame_rate": 24,
        "loop_count": 0,
        "filename_prefix": "HunyuanVideo",
        "format": "video/h264-mp4",
        "pix_fmt": "yuv420p",
        "crf": 19,
        "save_metadata": true,
        "trim_to_audio": false,
        "pingpong": false,
        "save_output": true,
        "videopreview": {
          "hidden": false,
          "paused": false,
          "params": {
            "filename": "HunyuanVideo_00182.mp4",
            "subfolder": "",
            "type": "output",
            "format": "video/h264-mp4",
            "frame_rate": 24,
            "workflow": "HunyuanVideo_00182.png",
            "fullpath": "/home/johnj/ComfyUI/output/HunyuanVideo_00182.mp4"
          },
          "muted": false
        }
      }
    },
    {
      "id": 45,
      "type": "VAEDecodeTiled",
      "pos": [
        604.5225830078125,
        -401.70220947265625
      ],
      "size": [
        210,
        150
      ],
      "flags": {},
      "order": 8,
      "mode": 0,
      "inputs": [
        {
          "name": "samples",
          "type": "LATENT",
          "link": 70
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 56
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            69
          ],
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "VAEDecodeTiled"
      },
      "widgets_values": [
        256,
        64,
        64,
        8
      ]
    },
    {
      "id": 44,
      "type": "VAELoaderMultiGPU",
      "pos": [
        208.21218872070312,
        -586.37841796875
      ],
      "size": [
        353.3572692871094,
        84.02234649658203
      ],
      "flags": {},
      "order": 0,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "VAE",
          "type": "VAE",
          "links": [
            56
          ],
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "VAELoaderMultiGPU"
      },
      "widgets_values": [
        "hunyuan_video_vae_bf16.safetensors",
        "cuda:1"
      ],
      "color": "#233",
      "bgcolor": "#355"
    },
    {
      "id": 53,
      "type": "HyVideoTextImageEncode",
      "pos": [
        -163.92579650878906,
        -51.38969421386719
      ],
      "size": [
        367.4625244140625,
        528.5474853515625
      ],
      "flags": {},
      "order": 6,
      "mode": 0,
      "inputs": [
        {
          "name": "text_encoders",
          "type": "HYVIDTEXTENCODER",
          "link": 74
        },
        {
          "name": "custom_prompt_template",
          "type": "PROMPT_TEMPLATE",
          "link": null,
          "shape": 7
        },
        {
          "name": "clip_l",
          "type": "CLIP",
          "link": null,
          "shape": 7
        },
        {
          "name": "image1",
          "type": "IMAGE",
          "link": 73,
          "shape": 7
        },
        {
          "name": "image2",
          "type": "IMAGE",
          "link": null,
          "shape": 7
        },
        {
          "name": "hyvid_cfg",
          "type": "HYVID_CFG",
          "link": null,
          "shape": 7
        }
      ],
      "outputs": [
        {
          "name": "hyvid_embeds",
          "type": "HYVIDEMBEDS",
          "links": [
            75
          ],
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "HyVideoTextImageEncode"
      },
      "widgets_values": [
        "The animal shown in <image> appears within its own natural setting, moving calmly or resting in place as a soft light casts delicate shadows across its form. Over the course of five seconds, it makes subtle shifts in posture or position, revealing small details of its features, such as the texture of its skin or fur, and the quiet rhythm of its breathing.",
        "::3",
        true,
        "video",
        ""
      ]
    },
    {
      "id": 54,
      "type": "LoadImage",
      "pos": [
        -526.0797119140625,
        233.78311157226562
      ],
      "size": [
        315,
        314
      ],
      "flags": {},
      "order": 1,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            73
          ],
          "slot_index": 0
        },
        {
          "name": "MASK",
          "type": "MASK",
          "links": null
        }
      ],
      "properties": {
        "Node name for S&R": "LoadImage"
      },
      "widgets_values": [
        "pasted/image (165).png",
        "image"
      ]
    },
    {
      "id": 49,
      "type": "DownloadAndLoadHyVideoTextEncoderMultiGPU",
      "pos": [
        -591.7539672851562,
        -37.14900588989258
      ],
      "size": [
        380.8912353515625,
        202
      ],
      "flags": {},
      "order": 2,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "hyvid_text_encoder",
          "type": "HYVIDTEXTENCODER",
          "links": [
            74
          ],
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "DownloadAndLoadHyVideoTextEncoderMultiGPU"
      },
      "widgets_values": [
        "xtuner/llava-llama-3-8b-v1_1-transformers",
        "openai/clip-vit-large-patch14",
        "bf16",
        false,
        2,
        "disabled",
        "cuda:0"
      ],
      "color": "#233",
      "bgcolor": "#355"
    },
    {
      "id": 3,
      "type": "HyVideoSampler",
      "pos": [
        255.96482849121094,
        -403.58502197265625
      ],
      "size": [
        315,
        630
      ],
      "flags": {},
      "order": 7,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "HYVIDEOMODEL",
          "link": 71
        },
        {
          "name": "hyvid_embeds",
          "type": "HYVIDEMBEDS",
          "link": 75
        },
        {
          "name": "samples",
          "type": "LATENT",
          "link": null,
          "shape": 7
        },
        {
          "name": "stg_args",
          "type": "STGARGS",
          "link": null,
          "shape": 7
        },
        {
          "name": "context_options",
          "type": "HYVIDCONTEXT",
          "link": null,
          "shape": 7
        },
        {
          "name": "feta_args",
          "type": "FETAARGS",
          "link": null,
          "shape": 7
        },
        {
          "name": "teacache_args",
          "type": "TEACACHEARGS",
          "link": null,
          "shape": 7
        }
      ],
      "outputs": [
        {
          "name": "samples",
          "type": "LATENT",
          "links": [
            70
          ],
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "HyVideoSampler"
      },
      "widgets_values": [
        768,
        1216,
        101,
        30,
        7.5,
        7.5,
        5770521,
        "fixed",
        true,
        1,
        "FlowMatchDiscreteScheduler"
      ]
    },
    {
      "id": 52,
      "type": "HyVideoModelLoaderDiffSynthMultiGPU",
      "pos": [
        -217.43194580078125,
        -401.6243896484375
      ],
      "size": [
        441,
        218
      ],
      "flags": {},
      "order": 3,
      "mode": 0,
      "inputs": [
        {
          "name": "compile_args",
          "type": "COMPILEARGS",
          "link": null,
          "shape": 7
        },
        {
          "name": "block_swap_args",
          "type": "BLOCKSWAPARGS",
          "link": null,
          "shape": 7
        },
        {
          "name": "lora",
          "type": "HYVIDLORA",
          "link": null,
          "shape": 7
        }
      ],
      "outputs": [
        {
          "name": "model",
          "type": "HYVIDEOMODEL",
          "links": [
            71
          ],
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "HyVideoModelLoaderDiffSynthMultiGPU"
      },
      "widgets_values": [
        "hunyuan_video_FastVideo_720_fp8_e4m3fn.safetensors",
        "bf16",
        "fp8_e4m3fn_fast",
        "sageattn_varlen",
        "cuda:0",
        "cuda:1"
      ],
      "color": "#233",
      "bgcolor": "#355"
    },
    {
      "id": 57,
      "type": "Note",
      "pos": [
        256.481689453125,
        293.84710693359375
      ],
      "size": [
        389.5359191894531,
        349.2815856933594
      ],
      "flags": {},
      "order": 4,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "Explanation of Memory Constraints and OOM Behavior",
      "properties": {},
      "widgets_values": [
        "The settings in this workflow deliberately push memory usage beyond what a single 24GB RTX 3090 can handle. As a result, UNet blocks must be offloaded to an offload_device, which is assumed to be a second 24GB RTX 3090. The chosen resolution and number of frames illustrate that one-megapixel image size videos over four seconds long can be generated—even though it exceeds the primary GPU's native memory capacity using the \"just-in-time\" DiffSynth block-swapping approach. The DiffSynth JiT algorithm is straightforward, but not optimized for speed.\n\n**Expected OOM Behavior**\n\n* One Initial \"Out of Memory\"\nSeeing a single OOM error at the start is normal for this workflow. It happens because kijai's HunyuanVideo Sampler node initially attempts a full load on \"device\", even if it will surpass available VRAM. A second attempt using the same generation parameters will correctly trigger the offload process to \"offload_device\".\n\n* Repeated OOM Errors \nIf you keep getting OOM errors with the same settings (beyond the first one), then the requirements of your generation parameters still exceed what your system—even with offloading—can manage. You may need to lower resolution, shorten video length, or upgrade hardware resources."
      ],
      "color": "#233",
      "bgcolor": "#355"
    },
    {
      "id": 51,
      "type": "Note",
      "pos": [
        -793.3005981445312,
        -466.9315490722656
      ],
      "size": [
        564.3460693359375,
        355.50164794921875
      ],
      "flags": {},
      "order": 5,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "****FIRST ATTEMPT LOADS ONLY ON PRIMARY DEVICE, POSSIBLE OOM****",
      "properties": {},
      "widgets_values": [
        "The MultiGPU implementation for HunyuanVideo now offers two approaches:\n1. The original workflow (examples/hunyuanvideowrapper_native_vae.json)\n2. A new experimental DiffSynth-enabled workflow that enables more efficient multi-GPU usage (examples/hunyuanvideowrapper_DiffSynth.json)\n\nNew DiffSynth-Based Workflow (Experimental - THIS WORKFLOW):\n* Uses the \"HyVideoModelLoaderDiffSynthMultiGPU\" node which implements DiffSynth's memory management approach with TWO device selections\n* Adds a second device selector \"offload_device\" specifically for model offloading\n* Automatically enables efficient block swapping between GPUs via kijai's adaptation of the DiffSynth methodology\n* Provides better memory utilization by keeping actively computed blocks in VRAM\n* Assumes a 2-device solution and sets \"force_offload\" to \"true\" to avoid VAE loader OOM issues. A third 3090, for instance could be used and thus the VAE would stay in memory as well\n\nKnown Behaviors:\n* Initial OOM errors are expected and consistent with the underlying implementation, occurring in the attention mechanism of the first double block\n* Second attempts typically succeed regardless of offload device selection (CPU or GPU)\n* When running, the secondary device shows active utilization, confirming proper block swapping\n\n***** Will require a second attempt if first generation fails with OOM****\n\nNOTE: The original workflow remains the recommended stable approach. The DiffSynth-based version is provided as an experimental alternative for users who want to explore more aggressive memory optimization strategies to extend either resolution or duration options at the expense of speed."
      ],
      "color": "#233",
      "bgcolor": "#355"
    }
  ],
  "links": [
    [
      56,
      44,
      0,
      45,
      1,
      "VAE"
    ],
    [
      69,
      45,
      0,
      34,
      0,
      "IMAGE"
    ],
    [
      70,
      3,
      0,
      45,
      0,
      "LATENT"
    ],
    [
      71,
      52,
      0,
      3,
      0,
      "HYVIDEOMODEL"
    ],
    [
      73,
      54,
      0,
      53,
      3,
      "IMAGE"
    ],
    [
      74,
      49,
      0,
      53,
      0,
      "HYVIDTEXTENCODER"
    ],
    [
      75,
      53,
      0,
      3,
      1,
      "HYVIDEMBEDS"
    ]
  ],
  "groups": [],
  "config": {},
  "extra": {
    "ds": {
      "scale": 0.797202450000112,
      "offset": [
        1219.7255813472686,
        777.2824223551936
      ]
    },
    "ue_links": [],
    "VHS_latentpreview": false,
    "VHS_latentpreviewrate": 0
  },
  "version": 0.4
}